{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjQ-UFLHno9F",
        "colab_type": "text"
      },
      "source": [
        "# HYPERPARAMETERS: Type of pooling\n",
        "In this document the implementation of different pooling methods will be discussed. The different pooling methods used are the following:\n",
        "\n",
        "*   Maximum\n",
        "*   Average\n",
        "*   Nothing\n",
        "\n",
        "The additions to the code provided are explained in the code itself.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn5vra55moKC",
        "colab_type": "code",
        "outputId": "8997d6d1-2043-43c7-d6ce-849ac6a667e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "!pip install pillow==5.4.1\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "# The tabulate library is used to show the final results\n",
        "!pip install tabulate"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow==5.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 3.4MB/s \n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Found existing installation: Pillow 6.2.2\n",
            "    Uninstalling Pillow-6.2.2:\n",
            "      Successfully uninstalled Pillow-6.2.2\n",
            "Successfully installed pillow-5.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.17.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (42.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (0.8.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pNXx9mHDCt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from tabulate import tabulate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXWeTcVsDEE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 20\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eSWZubf_jD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    # We change the constructor of this class in order to allow different types of pooling\n",
        "    def __init__(self, pooling_type): \n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc1Nth = nn.Linear(20*20*50, 500) # In the case of no pooling a different layer must be used because the input size is different\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        self.pooling_type = pooling_type\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        \n",
        "        if(self.pooling_type == \"max\"):\n",
        "          x = F.max_pool2d(x, 2, 2)\n",
        "          x = F.relu(self.conv2(x))\n",
        "          x = F.max_pool2d(x, 2, 2)\n",
        "          x = x.view(-1, 4*4*50)\n",
        "          x = F.relu(self.fc1(x))\n",
        "\n",
        "        elif(self.pooling_type == \"avg\"):\n",
        "          x = F.avg_pool2d(x, 2, 2)\n",
        "          x = F.relu(self.conv2(x))\n",
        "          x = F.avg_pool2d(x, 2, 2)\n",
        "          x = x.view(-1, 4*4*50)\n",
        "          x = F.relu(self.fc1(x))\n",
        "        else:\n",
        "          x = F.relu(self.conv2(x))\n",
        "          x = x.view(-1, 20*20*50)\n",
        "          x = F.relu(self.fc1Nth(x))\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlh75VbdLtLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader): \n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target) \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCYX74TPLyeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, device, loader):\n",
        "    \n",
        "    model.eval()  # let's put the model in evaluation mode\n",
        "\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():  # we don't need gradient computation at all\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            validation_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    validation_loss /= len(loader.dataset)\n",
        "    validation_accuracy = 100. * correct / len(loader.dataset)\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        validation_loss, correct, len(loader.dataset),\n",
        "        validation_accuracy))\n",
        "    \n",
        "    return validation_loss, validation_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNeCkJVsLzIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "03599732-79d8-4840-fbf0-ca2314367b84"
      },
      "source": [
        "train_batch_size = 128\n",
        "\n",
        "mnist_mean = 0.1307\n",
        "mnist_stddev = 0.3081\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data',\n",
        "                   train=True,\n",
        "                   download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((mnist_mean,), (mnist_stddev,))\n",
        "                   ])),\n",
        "    batch_size=train_batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "valid_batch_size = 1000\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data',\n",
        "                   train=False,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((mnist_mean,), (mnist_stddev,))\n",
        "                   ])),\n",
        "    batch_size=valid_batch_size,\n",
        "    shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 20198287.22it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 313950.99it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5705702.15it/s]                           \n",
            "8192it [00:00, 128136.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bnP0eUfG_kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_net(type, device):\n",
        "  train_losses = []\n",
        "  valid_losses = []\n",
        "  valid_x = []\n",
        "  valid_accuracy = []\n",
        "  # A new model is used for each pooling method\n",
        "  model = Net(type).to(device)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "\n",
        "  print('\\x1b[1;31m'+'\\n\\tType of pooling: {}\\t'.format(type)+'\\033[0;30m')\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "      epoch_losses = train(80, model, device, train_loader, optimizer, epoch)\n",
        "      train_losses.extend(epoch_losses)\n",
        "      valid_loss, valid_acc = validate(model, device, valid_loader)\n",
        "      valid_losses.append([valid_loss])\n",
        "      valid_accuracy.append(valid_acc)\n",
        "      valid_x.append(len(train_losses) - 1)\n",
        "      \n",
        "\n",
        "  plt.gcf().clear()\n",
        "  plt.plot(train_losses, 'b-')\n",
        "  plt.plot(valid_x, valid_losses, 'r-')\n",
        "  plt.show()\n",
        "  # In this implementation we also want to see the validation accuracy\n",
        "  return valid_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIc5k23nMlA5",
        "colab_type": "code",
        "outputId": "fd7777e8-d1b7-4f39-f972-b4516d22e682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "pooling = [\"max\",\"avg\",\"nothing\"]\n",
        "trainloss={\"max\":[\"Maximum\"], \"avg\":[\"Average\"], \"nothing\":[\"Nothing\"]}\n",
        "\n",
        "# We run three training sessions, one for each pooling method\n",
        "for type in pooling:\n",
        "  trainloss[type].extend(train_net(type, device))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(tabulate([trainloss[\"max\"], trainloss[\"avg\"], trainloss[\"nothing\"]], [\"Epoch\", 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;31m\n",
            "\tType of pooling: max\t\u001b[0;30m\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.282498\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.580224\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.342452\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.185716\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.370162\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.124976\n",
            "\n",
            "Validation set: Average loss: 0.1525, Accuracy: 9552/10000 (95.52%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.218684\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.102962\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.162518\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.123956\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.197738\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.097816\n",
            "\n",
            "Validation set: Average loss: 0.0896, Accuracy: 9730/10000 (97.30%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.096523\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.130213\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.050417\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.084786\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.167129\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.052888\n",
            "\n",
            "Validation set: Average loss: 0.0760, Accuracy: 9768/10000 (97.68%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.077061\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.063681\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.105777\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.039258\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.196056\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.102639\n",
            "\n",
            "Validation set: Average loss: 0.0558, Accuracy: 9834/10000 (98.34%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.041470\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.042136\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.020163\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.019046\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.044770\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.062086\n",
            "\n",
            "Validation set: Average loss: 0.0446, Accuracy: 9863/10000 (98.63%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.044542\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.059256\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.072020\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.031629\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.070338\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.007051\n",
            "\n",
            "Validation set: Average loss: 0.0421, Accuracy: 9861/10000 (98.61%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.107570\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.036944\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.017619\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.021304\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.046205\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.046184\n",
            "\n",
            "Validation set: Average loss: 0.0420, Accuracy: 9857/10000 (98.57%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.062659\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.025202\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.009975\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.071738\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.039334\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.063274\n",
            "\n",
            "Validation set: Average loss: 0.0371, Accuracy: 9874/10000 (98.74%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.028470\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.008107\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.024914\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.055921\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.016580\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.032137\n",
            "\n",
            "Validation set: Average loss: 0.0367, Accuracy: 9882/10000 (98.82%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.016958\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.015414\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.017946\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.025788\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.017550\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.027381\n",
            "\n",
            "Validation set: Average loss: 0.0348, Accuracy: 9879/10000 (98.79%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;31m\n",
            "\tType of pooling: avg\t\u001b[0;30m\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298285\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.674862\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.517735\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.500943\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.520862\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.424348\n",
            "\n",
            "Validation set: Average loss: 0.2901, Accuracy: 9167/10000 (91.67%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.288438\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.242042\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.244201\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.187071\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.162587\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.170735\n",
            "\n",
            "Validation set: Average loss: 0.1810, Accuracy: 9474/10000 (94.74%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.201878\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.146500\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.216832\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.183188\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.174220\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.127725\n",
            "\n",
            "Validation set: Average loss: 0.1212, Accuracy: 9630/10000 (96.30%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.118692\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.198436\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.064642\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.168044\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.114237\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.053252\n",
            "\n",
            "Validation set: Average loss: 0.1017, Accuracy: 9698/10000 (96.98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.087161\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.151842\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.064758\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.098014\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.152751\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.053566\n",
            "\n",
            "Validation set: Average loss: 0.0875, Accuracy: 9728/10000 (97.28%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.085328\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.042851\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.111327\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.162070\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.164608\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.081260\n",
            "\n",
            "Validation set: Average loss: 0.0707, Accuracy: 9777/10000 (97.77%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.059669\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.094000\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.095746\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.094006\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.043522\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.056348\n",
            "\n",
            "Validation set: Average loss: 0.0609, Accuracy: 9810/10000 (98.10%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.087900\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.029155\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.097568\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.050673\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.019374\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.101975\n",
            "\n",
            "Validation set: Average loss: 0.0642, Accuracy: 9785/10000 (97.85%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.035818\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.026621\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.081662\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.032865\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.019442\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.068470\n",
            "\n",
            "Validation set: Average loss: 0.0530, Accuracy: 9828/10000 (98.28%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.081105\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.050589\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.125196\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.083968\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.062989\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.028525\n",
            "\n",
            "Validation set: Average loss: 0.0491, Accuracy: 9841/10000 (98.41%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;31m\n",
            "\tType of pooling: nothing\t\u001b[0;30m\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301605\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.405962\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.295821\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.171345\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.159069\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.148118\n",
            "\n",
            "Validation set: Average loss: 0.1493, Accuracy: 9559/10000 (95.59%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.144465\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.157239\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.098684\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.118894\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.156791\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.060789\n",
            "\n",
            "Validation set: Average loss: 0.0848, Accuracy: 9748/10000 (97.48%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.054326\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.061708\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.053018\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.015360\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.105324\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.103563\n",
            "\n",
            "Validation set: Average loss: 0.0722, Accuracy: 9778/10000 (97.78%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.033077\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.045535\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.045950\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.126351\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.041132\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.048753\n",
            "\n",
            "Validation set: Average loss: 0.0573, Accuracy: 9824/10000 (98.24%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.078528\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.035960\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.010452\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.073396\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.027948\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.060708\n",
            "\n",
            "Validation set: Average loss: 0.0504, Accuracy: 9846/10000 (98.46%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.040386\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.042318\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.012185\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.048920\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.016695\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.028414\n",
            "\n",
            "Validation set: Average loss: 0.0488, Accuracy: 9836/10000 (98.36%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.025257\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.011809\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.005535\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.025226\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.041300\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.064156\n",
            "\n",
            "Validation set: Average loss: 0.0469, Accuracy: 9853/10000 (98.53%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.031488\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.023113\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.006330\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.027420\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.030179\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.024068\n",
            "\n",
            "Validation set: Average loss: 0.0427, Accuracy: 9862/10000 (98.62%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.009756\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.006981\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.006000\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.014592\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.010897\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.032782\n",
            "\n",
            "Validation set: Average loss: 0.0415, Accuracy: 9862/10000 (98.62%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.022577\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.001068\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.001378\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.016538\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.040535\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.032910\n",
            "\n",
            "Validation set: Average loss: 0.0392, Accuracy: 9868/10000 (98.68%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOYKBTkSUIxjoREQ5goFORJQj/h820uolx9CeHQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch        1      2      3      4      5      6      7      8      9     10\n",
            "-------  -----  -----  -----  -----  -----  -----  -----  -----  -----  -----\n",
            "Maximum  95.52  97.3   97.68  98.34  98.63  98.61  98.57  98.74  98.82  98.79\n",
            "Average  91.67  94.74  96.3   96.98  97.28  97.77  98.1   97.85  98.28  98.41\n",
            "Nothing  95.59  97.48  97.78  98.24  98.46  98.36  98.53  98.62  98.62  98.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOwxa7m6_pu8",
        "colab_type": "text"
      },
      "source": [
        "#Conclusions\n",
        "After running the experiment, it can be concluded that the best pooling method is, with the dataset provided, the Maximum-Pooling. This shows that the higher value elements are more important than the rest of the values. This can also be seen looking at the average pooling method. With this method a lower accuracy and a higher loss is obtained. This is beacuse it takes every value into account with the same importance (so the maximum value has less importance than before). Finally without using pooling, the accuracy rate and loss obtained is in between the previous two pooling methods. This method would also require more computational capacity because no pooling is used and it works with more samples."
      ]
    }
  ]
}